<!DOCTYPE HTML>
<html lang="en" class="ayu sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Reading and Writing JSON Data - SynxDB 2 Documentation</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "ayu" : "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">SynxDB 2 Documentation</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                        &nbsp;&nbsp;&nbsp;&nbsp;
                        <a href="https://www.synxdata.com/"><img id="fa fa-print" src="../SYNX-Text-and-Circular-Logo-142x28-White-text-Black-background.png" alt="Synx Data Labs Logo"/></a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="reading-and-writing-json-data-in-hdfs"><a class="header" href="#reading-and-writing-json-data-in-hdfs">Reading and Writing JSON Data in HDFS</a></h1>
<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<p>Use the PXF HDFS Connector to read and write JSON-format data. This section describes how to use PXF and external tables to access and write JSON data in HDFS.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites"><a id="prereq"></a>Prerequisites</a></h2>
<p>Ensure that you have met the PXF Hadoop <a href="access_hdfs.html#hadoop_prereq">Prerequisites</a> before you attempt to read data from or write data to HDFS.</p>
<h2 id="working-with-json-data"><a class="header" href="#working-with-json-data"><a id="hdfsjson_work"></a>Working with JSON Data</a></h2>
<p>JSON is a text-based data-interchange format. A JSON data file contains one or more JSON objects. A JSON object is a collection of unordered name/value pairs. A value can be a string, a number, true, false, null, an object, or an array. You can define nested JSON objects and arrays.</p>
<p>JSON data is typically stored in a file with a <code>.json</code> or <code>.jsonl</code> (JSON Lines) suffix as described in the sections below.</p>
<h3 id="about-the-pxf-json-data-access-modes"><a class="header" href="#about-the-pxf-json-data-access-modes"><a id="topic_jsonmodes"></a>About the PXF JSON Data Access Modes</a></h3>
<p>PXF supports two data access modes for JSON files. The default mode expects one full JSON record per row (JSONL). PXF also supports an access mode that expects one JSON object per file where the JSON records may (but are not required to) span multiple lines.</p>
<h4 id="single-object-per-row"><a class="header" href="#single-object-per-row"><a id="jsonl"></a>Single Object Per Row</a></h4>
<p>A JSON file can contain a single JSON object per row, where each row represents a database tuple. A JSON file that PXF reads that contains a single object per row may have any or no suffix. When writing, PXF creates the file with a <code>.jsonl</code> suffix.</p>
<p>Excerpt of sample single-object-per-row JSON data file:</p>
<pre><code class="language-pre">{"id":1,"color":"red"}
{"id":2,"color":"yellow"}
{"id":3,"color":"green"}
</code></pre>
<p>Refer to <a href="https://jsonlines.org/">JSON Lines</a> for detailed information about this JSON syntax.</p>
<h4 id="single-object-per-file"><a class="header" href="#single-object-per-file"><a id="arrayobject"></a>Single Object Per File</a></h4>
<p>A JSON file can also contain a single, named, root level JSON object whose value is an array of JSON objects. When reading, the array may contain objects with arbitrary complexity and nesting, and PXF forms database tuples from objects that have a property named the same as that specified for the <code>IDENTIFIER</code> (discussed below). When writing, each JSON object in the array represents a database tuple. JSON files of this type have the <code>.json</code> suffix.</p>
<p>In the following example JSON data file, the root-level <code>records</code> object is an array of three objects (tuples):</p>
<pre><code class="language-pre">{"records":[
{"id":1,"color":"red"}
,{"id":2,"color":"yellow"}
,{"id":3,"color":"green"}
]}
</code></pre>
<p>The records in the single JSON object may also span multiple lines:</p>
<pre><code class="language-pre">{
  "records":[
    {
      "id":1,
      "color":"red"
    },
    {
      "id":2,
      "color":"yellow"
    },
    {
      "id":3,
      "color":"green"
    }
  ]
}
</code></pre>
<p>Refer to <a href="http://www.json.org/">Introducing JSON</a> for detailed information about this JSON syntax.</p>
<h2 id="data-type-mapping"><a class="header" href="#data-type-mapping"><a id="datatypemap"></a>Data Type Mapping</a></h2>
<p>To represent JSON data in SynxDB, map data values that use a primitive data type to SynxDB columns of the same type. JSON supports complex data types including projections and arrays.</p>
<h3 id="read-mapping"><a class="header" href="#read-mapping"><a id="datatypemap_read"></a>Read Mapping</a></h3>
<p>PXF uses the following data type mapping when reading JSON data:</p>
<div class="table-wrapper"><table><thead><tr><th>JSON Data Type</th><th>PXF/SynxDB Data Type</th></tr></thead><tbody>
<tr><td>boolean</td><td>boolean</td></tr>
<tr><td>number</td><td>{ bigint | float8 | integer | numeric | real | smallint }</td></tr>
<tr><td>string</td><td>text</td></tr>
<tr><td>string (base64-encoded value)</td><td>bytea</td></tr>
<tr><td>string (date, time, timestamp, timestamptz in a text format that SynxDB understands)<sup>1</sup></td><td>{ date | time | timestamp | timestamptz }</td></tr>
<tr><td>Array (one dimension) of type boolean[]</td><td>boolean[]</td></tr>
<tr><td>Array (one dimension) of type number[]</td><td>{ bigint[] | float8[] | integer[] | numeric[] | real[] | smallint[] }</td></tr>
<tr><td>Array (one dimension) of type string[] (base64-encoded value)</td><td>bytea[]</td></tr>
<tr><td>Array (one dimension) of type string[] (date, time, timestamp in a text format that SynxDB understands)<sup>1</sup></td><td>{ date[] | time[] | timestamp[] | timestamptz[] }</td></tr>
<tr><td>Array (one dimension) of type string[]</td><td>text[]</td></tr>
<tr><td>Array of other types</td><td>text[]</td></tr>
<tr><td>Object</td><td>Use dot <code>.</code> notation to specify each level of projection (nesting) to a member of a primitive or Array type.</td></tr>
<tr><td><sup>1</sup> PXF returns an error if SynxDB cannot convert the date or time string to the target type.</td><td></td></tr>
</tbody></table>
</div>
<p>When reading, you can use N-level projection to map members of nested objects and arrays to primitive data types.</p>
<h3 id="write-mapping"><a class="header" href="#write-mapping"><a id="datatypemap_write"></a>Write Mapping</a></h3>
<p>PXF supports writing primitive types and single dimension arrays of primitive types. PXF supports writing other complex types to JSON as string.</p>
<p>PXF uses the following data type mapping when writing JSON data:</p>
<div class="table-wrapper"><table><thead><tr><th>PXF/SynxDB Data Type</th><th>JSON Data Type</th></tr></thead><tbody>
<tr><td>bigint, float8, integer, numeric, real, smallint</td><td>number</td></tr>
<tr><td>boolean</td><td>boolean</td></tr>
<tr><td>bpchar, text, varchar</td><td>string</td></tr>
<tr><td>bytea</td><td>string (base64-encoded value)</td></tr>
<tr><td>date, time, timestamp, timestamptz</td><td>string</td></tr>
<tr><td>boolean[]</td><td>boolean[]</td></tr>
<tr><td>bigint[], float8[], int[], numeric[], real[], smallint[]</td><td>number[]</td></tr>
<tr><td>bytea[]</td><td>string[] (base64-encoded value)</td></tr>
<tr><td>date[], time[], timestamp[], timestamptz[]</td><td>string[]</td></tr>
</tbody></table>
</div>
<h2 id="about-using-projection-read"><a class="header" href="#about-using-projection-read"><a id="projection"></a>About Using Projection (Read)</a></h2>
<p>In the example JSON data file excerpt below, <code>user</code> is an object composed of fields named <code>id</code> and <code>location</code>:</p>
<pre><code class="language-json">  {
    "created_at":"MonSep3004:04:53+00002013",
    "id_str":"384529256681725952",
    "user": {
      "id":31424214,
      "location":"COLUMBUS"
    },
    "coordinates":{
      "type":"Point",
      "values":[
         13,
         99
      ]
    }
  }
</code></pre>
<p>To specify the nested fields in the <code>user</code> object directly as SynxDB external table columns, use <code>.</code> projection:</p>
<pre><code class="language-pre">user.id
user.location
</code></pre>
<p><code>coordinates</code> is an object composed of a text field named <code>type</code> and an array of integers named <code>values</code>.</p>
<p>To read all of the elements of the <code>values</code> array in a single column, define the corresponding SynxDB external table column as type <code>int[]</code>.</p>
<pre><code class="language-pre">"coordinates.values" int[]
</code></pre>
<h2 id="creating-the-external-table"><a class="header" href="#creating-the-external-table"><a id="profile_cet"></a>Creating the External Table</a></h2>
<p>Use the <code>hdfs:json</code> profile to read or write JSON-format data in HDFS. The following syntax creates a SynxDB external table that references such a file:</p>
<pre><code class="language-sql">CREATE [WRITABLE] EXTERNAL TABLE &lt;table_name&gt;
    ( &lt;column_name&gt; &lt;data_type&gt; [, ...] | LIKE &lt;other_table&gt; )
LOCATION ('pxf://&lt;path-to-hdfs-file&gt;?PROFILE=hdfs:json[&amp;SERVER=&lt;server_name&gt;][&amp;&lt;custom-option&gt;=&lt;value&gt;[...]]')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import'|'pxfwritable_export')
[DISTRIBUTED BY (&lt;column_name&gt; [, ... ] ) | DISTRIBUTED RANDOMLY];
</code></pre>
<p>The specific keywords and values used in the SynxDB <a href="../ref_guide/sql_commands/CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a> command are described in the table below.</p>
<div class="table-wrapper"><table><thead><tr><th>Keyword</th><th>Value</th></tr></thead><tbody>
<tr><td>&lt;path‑to‑hdfs‑file&gt;</td><td>The path to the directory or file in the HDFS data store. When the <code>&lt;server_name&gt;</code> configuration includes a <a href="cfg_server.html#pxf-fs-basepath"><code>pxf.fs.basePath</code></a> property setting, PXF considers &lt;path‑to‑hdfs‑file&gt; to be relative to the base path specified. Otherwise, PXF considers it to be an absolute path. &lt;path‑to‑hdfs‑file&gt; must not specify a relative path nor include the dollar sign (<code>$</code>) character.</td></tr>
<tr><td>PROFILE</td><td>The <code>PROFILE</code> keyword must specify <code>hdfs:json</code>.</td></tr>
<tr><td>SERVER=&lt;server_name&gt;</td><td>The named server configuration that PXF uses to access the data. PXF uses the <code>default</code> server if not specified.</td></tr>
<tr><td>&lt;custom‑option&gt;</td><td>&lt;custom-option&gt;s for read and write operations are identified below.</td></tr>
<tr><td>FORMAT ‘CUSTOM’</td><td>Use <code>FORMAT</code> ‘<code>CUSTOM</code>’ with <code>(FORMATTER='pxfwritable_export')</code> (write) or <code>(FORMATTER='pxfwritable_import')</code> (read).</td></tr>
</tbody></table>
</div>
<p><a id="customopts"></a>
PXF supports reading from and writing to JSON files that contain either an object per row (the default) or that contain a JSON single object. When the JSON file(s) that you want to read or write contains a single object, you must provide an <code>IDENTIFIER</code> &lt;custom-option&gt; and value. Use this option to identify the name of a field whose parent JSON object you want PXF to return or write as an individual tuple.</p>
<p>The <code>hdfs:json</code> profile supports the following custom <strong>read</strong> options:</p>
<div class="table-wrapper"><table><thead><tr><th>Option Keyword</th><th>Description</th></tr></thead><tbody>
<tr><td>IDENTIFIER=&lt;value&gt;</td><td>When the JSON data that you are reading is comprised of a single JSON object, you must specify an <code>IDENTIFIER</code> to identify the name of the field whose parent JSON object you want PXF to return as an individual tuple.</td></tr>
<tr><td>SPLIT_BY_FILE=&lt;boolean&gt;</td><td>Specify how PXF splits the data in &lt;path-to-hdfs-file&gt;. The default value is <code>false</code>, PXF creates multiple splits for each file that it will process in parallel. When set to <code>true</code>, PXF creates and processes a single split per file.</td></tr>
<tr><td>IGNORE_MISSING_PATH=&lt;boolean&gt;</td><td>Specify the action to take when &lt;path-to-hdfs-file&gt; is missing or invalid. The default value is <code>false</code>, PXF returns an error in this situation. When the value is <code>true</code>, PXF ignores missing path errors and returns an empty fragment.</td></tr>
</tbody></table>
</div><div class="note"><b>Note:</b> When a nested object in a single object JSON file includes a field with the same name as that of a parent object field <i>and</i> the field name is also specified as the <code>IDENTIFIER</code>, there is a possibility that PXF could return incorrect results. Should you need to, you can work around this edge case by compressing the JSON file, and using PXF to read the compressed file.</div>
<p>The <code>hdfs:json</code> profile supports the following custom <strong>write</strong> options:</p>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Value Description</th></tr></thead><tbody>
<tr><td>ROOT=&lt;value&gt;</td><td>When writing to a single JSON object, identifies the name of the root-level object attribute.</td></tr>
<tr><td>COMPRESSION_CODEC</td><td>The compression codec alias. Supported compression codecs for writing json data include: <code>default</code>, <code>bzip2</code>, <code>gzip</code>, and <code>uncompressed</code>. If this option is not provided, SynxDB performs no data compression.</td></tr>
<tr><td>DISTRIBUTED BY</td><td>If you are loading data from an existing SynxDB table into the writable external table, consider specifying the same distribution policy or <code>&lt;column_name&gt;</code> on both tables. Doing so will avoid extra motion of data between segments on the load operation.</td></tr>
</tbody></table>
</div>
<p>When you specify compression for a JSON write operation, PXF names the files that it writes <code>&lt;basename&gt;.&lt;json_file_type&gt;.&lt;compression_extension&gt;</code>. For example: <code>jan_sales.jsonl.gz</code>.</p>
<h2 id="read-examples"><a class="header" href="#read-examples"><a id="json_read"></a>Read Examples</a></h2>
<h3 id="example-data-sets"><a class="header" href="#example-data-sets"><a id="example_datasets"></a>Example Data Sets</a></h3>
<p>In upcoming read examples, you use both JSON access modes to operate on a sample data set. The schema of the sample data set defines objects with the following member names and value data types:</p>
<ul>
<li>
<p>“created_at” - text</p>
</li>
<li>
<p>“id_str” - text</p>
</li>
<li>
<p>“user” - object</p>
<ul>
<li>“id” - integer</li>
<li>“location” - text</li>
</ul>
</li>
<li>
<p>“coordinates” - object (optional)</p>
<ul>
<li>
<p>“type” - text</p>
</li>
<li>
<p>“values” - array</p>
<ul>
<li>[0] - integer</li>
<li>[1] - integer</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The data set for the single-object-per-row (JSONL) access mode follows:</p>
<pre><code class="language-pre">{"created_at":"FriJun0722:45:03+00002013","id_str":"343136551322136576","user":{"id":395504494,"location":"NearCornwall"},"coordinates":{"type":"Point","values": [ 6, 50 ]}},
{"created_at":"FriJun0722:45:02+00002013","id_str":"343136547115253761","user":{"id":26643566,"location":"Austin,Texas"}, "coordinates": null},
{"created_at":"FriJun0722:45:02+00002013","id_str":"343136547136233472","user":{"id":287819058,"location":""}, "coordinates": null}
</code></pre>
<p>The data set for the single-object-per-file JSON access mode follows:</p>
<pre><code class="language-json">{
  "root":[
    {
      "record_obj":{
        "created_at":"MonSep3004:04:53+00002013",
        "id_str":"384529256681725952",
        "user":{
          "id":31424214,
          "location":"COLUMBUS"
        },
        "coordinates":null
      },
      "record_obj":{
        "created_at":"MonSep3004:04:54+00002013",
        "id_str":"384529260872228864",
        "user":{
          "id":67600981,
          "location":"KryberWorld"
        },
        "coordinates":{
          "type":"Point",
          "values":[
             8,
             52
          ]
        }
      }
    }
  ]
}
</code></pre>
<p>You will create JSON files for the sample data sets and add them to HDFS in the next section.</p>
<h3 id="loading-the-sample-json-data-to-hdfs"><a class="header" href="#loading-the-sample-json-data-to-hdfs"><a id="jsontohdfs"></a>Loading the Sample JSON Data to HDFS</a></h3>
<p>The PXF HDFS connector can read and write native JSON stored in HDFS.</p>
<p>Copy and paste the object-per-row JSON sample data set above to a file named <code>objperrow.jsonl</code>. Similarly, copy and paste the single object per file JSON record data set to a file named <code>singleobj.json</code>.</p>
<blockquote>
<p><strong>Note</strong> Ensure that there are <strong>no</strong> blank lines in your JSON files.</p>
</blockquote>
<p>Copy the JSON data files that you just created to your HDFS data store. Create the <code>/data/pxf_examples</code> directory if you did not do so in a previous exercise. For example:</p>
<pre><code class="language-shell">$ hdfs dfs -mkdir /data/pxf_examples
$ hdfs dfs -put objperrow.jsonl /data/pxf_examples/
$ hdfs dfs -put singleobj.json /data/pxf_examples/
</code></pre>
<p>Once the data is loaded to HDFS, you can use SynxDB and PXF to query and add to the JSON data.</p>
<h3 id="example-single-object-per-row-read"><a class="header" href="#example-single-object-per-row-read"><a id="read_example1"></a>Example: Single Object Per Row (Read)</a></h3>
<p>Use the following <a href="../ref_guide/sql_commands/CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a> SQL command to create a readable external table that references the single-object-per-row JSON data file and uses the PXF default server.</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE objperrow_json_tbl(
  created_at TEXT,
  id_str TEXT,
  "user.id" INTEGER,
  "user.location" TEXT,
  "coordinates.values" INTEGER[]
)
LOCATION('pxf://data/pxf_examples/objperrow.jsonl?PROFILE=hdfs:json')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
</code></pre>
<p>This table reads selected fields in the JSON file. Notice the use of <code>.</code> projection to access the nested fields in the <code>user</code> and <code>coordinates</code> objects.</p>
<p>To view the JSON data in the file, query the external table:</p>
<pre><code class="language-sql">SELECT * FROM objperrow_json_tbl;
</code></pre>
<p>To access specific elements of the <code>coordinates.values</code> array, you can specify the array subscript number in square brackets:</p>
<pre><code class="language-sql">SELECT "coordinates.values"[1], "coordinates.values"[2] FROM objperrow_json_tbl;
</code></pre>
<h3 id="example-single-object-per-file-read"><a class="header" href="#example-single-object-per-file-read"><a id="read_example2"></a>Example: Single Object Per File (Read)</a></h3>
<p>The SQL command to create a readable external table for a single object JSON file is very similar to that of the single object per row data set above. You must additionally specify the <code>LOCATION</code> clause <code>IDENTIFIER</code> keyword and an associated value. For example:</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE singleobj_json_tbl(
  created_at TEXT,
  id_str TEXT,
  "user.id" INTEGER,
  "user.location" TEXT,
  "coordinates.values" INTEGER[]
)
LOCATION('pxf://data/pxf_examples/singleobj.json?PROFILE=hdfs:json&amp;IDENTIFIER=created_at')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
</code></pre>
<p><code>created_at</code> identifies the member name of the first field in the JSON record <code>record_obj</code> in the sample data schema.</p>
<p>To view the JSON data in the file, query the external table:</p>
<pre><code class="language-sql">SELECT * FROM singleobj_json_tbl;
</code></pre>
<h3 id="other-methods-to-read-a-json-array"><a class="header" href="#other-methods-to-read-a-json-array"><a id="array_other"></a> Other Methods to Read a JSON Array</a></h3>
<p>Starting in version 6.2.0, PXF supports reading a JSON array into a <code>TEXT[]</code> column. PXF still supports the old methods of using array element projection or a single text-type column to read a JSON array. These access methods are described here.</p>
<h4 id="using-array-element-projection"><a class="header" href="#using-array-element-projection"><a id="arrayelproj"></a>Using Array Element Projection</a></h4>
<p>PXF supports accessing specific elements of a JSON array using the syntax <code>[n]</code> in the table definition to identify the specific element.</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE objperrow_json_tbl_aep(
  created_at TEXT,
  id_str TEXT,
  "user.id" INTEGER,
  "user.location" TEXT,
  "coordinates.values[0]" INTEGER,
  "coordinates.values[1]" INTEGER
)
LOCATION('pxf://data/pxf_examples/objperrow.jsonl?PROFILE=hdfs:json')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
</code></pre>
<p><strong>Note</strong>: When you use this method to identify specific array elements, PXF provides <em>only</em> those values to SynxDB, not the whole JSON array.</p>
<p>If your existing external table definition uses array element projection and you want to read the array into a <code>TEXT[]</code> column, you can use the <code>ALTER EXTERNAL TABLE</code> command to update the table definition. For example:</p>
<pre><code class="language-sql">ALTER EXTERNAL TABLE objperrow_json_tbl_aep DROP COLUMN "coordinates.values[0]", DROP COLUMN "coordinates.values[1]", ADD COLUMN "coordinates.values" TEXT[];
</code></pre>
<p>If you choose to alter the external table definition in this manner, be sure to update any existing queries on the external table to account for the changes to column name and type.</p>
<h4 id="specifying-a-single-text-type-column"><a class="header" href="#specifying-a-single-text-type-column"><a id="singletextcol"></a> Specifying a Single Text-type Column</a></h4>
<p>PXF supports accessing all of the elements within an array as a single string containing the serialized JSON array by defining the corresponding SynxDB table column with one of the following data types: <code>TEXT</code>, <code>VARCHAR</code>, or <code>BPCHAR</code>.</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE objperrow_json_tbl_stc(
  created_at TEXT,
  id_str TEXT,
  "user.id" INTEGER,
  "user.location" TEXT,
  "coordinates.values" TEXT
)
LOCATION('pxf://data/pxf_examples/objperrow.jsonl?PROFILE=hdfs:json')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
</code></pre>
<p>If you retrieve the JSON array in a single text-type column and wish to convert the JSON array serialized as <code>TEXT</code> back into a native SynxDB array type, you can use the example query below:</p>
<pre><code class="language-sql">SELECT user.id,
       ARRAY(SELECT json_array_elements_text(coordinates.values::json))::int[] AS coords
FROM objperrow_json_tbl_stc;
</code></pre>
<p><strong>Note</strong>: This conversion is possible only when you are using PXF with SynxDB 6.x; the function <code>json_array_elements_text()</code> is not available in SynxDB 5.x.</p>
<p>If your external table definition uses a single text-type column for a JSON array and you want to read the array into a <code>TEXT[]</code> column, you can use the <code>ALTER EXTERNAL TABLE</code> command to update the table definition. For example:</p>
<pre><code class="language-sql">ALTER EXTERNAL TABLE objperrow_json_tbl_stc ALTER COLUMN "coordinates.values" TYPE TEXT[];
</code></pre>
<p>If you choose to alter the external table definition in this manner, be sure to update any existing queries on the external table to account for the change in column type.</p>
<h2 id="writing-json-data"><a class="header" href="#writing-json-data"><a id="json_write"></a>Writing JSON Data</a></h2>
<p>To write JSON data, you create a writable external table that references the name of a directory on HDFS. When you insert records into the writable external table, PXF writes the block(s) of data that you insert to one or more files in the directory that you specified. In the default case (single object per row), PXF writes the data to a <code>.jsonl</code> file. When you specify a <code>ROOT</code> attribute (single object per file), PXF writes to a <code>.json</code> file.</p>
<blockquote>
<p><strong>Note</strong> When writing JSON data, PXF supports only scalar or one dimensional arrays of SynxDB data types. PXF does not support column projection when writing JSON data.</p>
</blockquote>
<p>Writable external tables can only be used for <code>INSERT</code> operations. If you want to query the data that you inserted, you must create a separate readable external table that references the HDFS directory and read from that table.</p>
<p>The write examples use a data schema similar to that of the read examples.</p>
<h3 id="example-single-object-per-row-write"><a class="header" href="#example-single-object-per-row-write"><a id="write_example1"></a>Example: Single Object Per Row (Write)</a></h3>
<p>In this example, we add data to a directory named <code>jsopr</code>.</p>
<p>Use the following <a href="../ref_guide/sql_commands/CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a> SQL command to create a writable external table that writes JSON data in single-object-per-row format and uses the PXF default server.</p>
<pre><code class="language-sql">CREATE WRITABLE EXTERNAL TABLE add_objperrow_json_tbl(
  created_at TEXT,
  id_str TEXT,
  id INTEGER,
  location TEXT,
  coordinates INTEGER[]
)
LOCATION('pxf://data/pxf_examples/jsopr?PROFILE=hdfs:json')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_export');
</code></pre>
<p>Write data to the table:</p>
<pre><code class="language-sql">INSERT INTO add_objperrow_json_tbl VALUES ( 'SunJun0912:59:07+00002013', '343136551111111111', 311111111, 'FarAway', '{ 6, 50 }' );
INSERT INTO add_objperrow_json_tbl VALUES ( 'MonJun1002:12:06+00002013', '343136557777777777', 377777777, 'NearHere', '{ 13, 93 }' );
</code></pre>
<p>Read the data that you just wrote. Recall that you must first create a readable external table:</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE jsopr_tbl(
  created_at TEXT,
  id_str TEXT,
  id INTEGER,
  location TEXT,
  coordinates INTEGER[]
)
LOCATION('pxf://data/pxf_examples/jsopr?PROFILE=hdfs:json')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
</code></pre>
<p>Query the table:</p>
<pre><code class="language-sql">SELECT * FROM jsopr_tbl;

        created_at         |       id_str       |    id     | location | coordinates 
---------------------------+--------------------+-----------+----------+-------------
 MonJun1002:12:06+00002013 | 343136557777777777 | 377777777 | NearHere | {13,93}
 SunJun0912:59:07+00002013 | 343136551111111111 | 311111111 | FarAway  | {6,50}
(2 rows)
</code></pre>
<p>View the files added to HDFS:</p>
<pre><code>$ hdfs dfs -cat /data/pxf_examples/jsopr/*
{"created_at":"SunJun0912:59:07+00002013","id_str":"343136551111111111","id":311111111,"location":"FarAway","coordinates":[6,50]}
{"created_at":"MonJun1002:12:06+00002013","id_str":"343136557777777777","id":377777777,"location":"NearHere","coordinates":[13,93]}
</code></pre>
<p>Notice that PXF creates a flat JSON structure.</p>
<h3 id="example-single-object-per-file-write"><a class="header" href="#example-single-object-per-file-write"><a id="write_example2"></a>Example: Single Object Per File (Write)</a></h3>
<p>Use the following <a href="../ref_guide/sql_commands/CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a> SQL command to create a writable external table that writes JSON data in single object format and uses the PXF default server.</p>
<p>You must specify the <code>ROOT</code> keyword and associated value in the <code>LOCATION</code> clause. For example:</p>
<pre><code class="language-sql">CREATE WRITABLE EXTERNAL TABLE add_singleobj_json_tbl(
  created_at TEXT,
  id_str TEXT,
  id INTEGER,
  location TEXT,
  coordinates INTEGER[]
)
LOCATION('pxf://data/pxf_examples/jso?PROFILE=hdfs:json&amp;ROOT=root')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_export');
</code></pre>
<p><code>root</code> identifies the name of the root attribute of the single object.</p>
<p>Write data to the table:</p>
<pre><code class="language-sql">INSERT INTO add_singleobj_json_tbl VALUES ( 'SunJun0912:59:07+00002013', '343136551111111111', 311111111, 'FarAway', '{ 6, 50 }' );
INSERT INTO add_singleobj_json_tbl VALUES ( 'WedJun1212:37:02+00002013', '333333333333333333', 333333333, 'NetherWorld', '{ 9, 63 }' );
</code></pre>
<p>Read the data that you just wrote. Recall that you must first create a new readable external table:</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE jso_tbl(
  created_at TEXT,
  id_str TEXT,
  id INTEGER,
  location TEXT,
  coordinates INTEGER[]
)
LOCATION('pxf://data/pxf_examples/jso?PROFILE=hdfs:json&amp;IDENTIFIER=created_at')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
</code></pre>
<p>The column names that you specify in the create command must match those of the writable external table. And recall that to read a JSON file that contains a single object, you must specify the <code>IDENTIFIER</code> option.</p>
<p>Query the table to read the data:</p>
<pre><code class="language-sql">SELECT * FROM jso_tbl;

        created_at         |       id_str       |    id     |   location   | coordinates 
---------------------------+--------------------+-----------+--------------+-------------
 WedJun1212:37:02+00002013 | 333333333333333333 | 333333333 | NetherWorld  | {9,63}
 SunJun0912:59:07+00002013 | 343136551111111111 | 311111111 | FarAway      | {6,50}
(2 rows)
</code></pre>
<p>View the files added to HDFS:</p>
<pre><code>$ hdfs dfs -cat /data/pxf_examples/jso/*
{"root":[
{"created_at":"SunJun0912:59:07+00002013","id_str":"343136551111111111","id":311111111,"location":"FarAway","coordinates":[6,50]}
]}
{"root":[
{"created_at":"WedJun1212:37:02+00002013","id_str":"333333333333333333","id":333333333,"location":"NetherWorld","coordinates":[9,63]}
]}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../pxf/hdfs_avro.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../pxf/hdfs_orc.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../pxf/hdfs_avro.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../pxf/hdfs_orc.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
